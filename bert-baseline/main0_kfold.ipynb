{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from transformers import RobertaTokenizer, RobertaModel, RobertaConfig\n",
    "from transformers import AdamW,get_linear_schedule_with_warmup,logging\n",
    "# from torch.utils.data import TensorDataset,SequentialSampler,RandomSampler,DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # 禁止hash随机化\n",
    "    torch.manual_seed(seed)\n",
    "setup_seed(2022)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33219 entries, 0 to 33218\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          33219 non-null  int64 \n",
      " 1   method      33219 non-null  object\n",
      " 2   user_agent  33219 non-null  object\n",
      " 3   url         33219 non-null  object\n",
      " 4   refer       33219 non-null  object\n",
      " 5   body        33219 non-null  object\n",
      " 6   label       33219 non-null  int64 \n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 1.8+ MB\n",
      "33219\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "train_files = glob.glob('../data/train/*.csv')\n",
    "\n",
    "df_train = pd.DataFrame()\n",
    "\n",
    "for filepath in tqdm(train_files):\n",
    "    df = pd.read_csv(filepath)\n",
    "    df_train = pd.concat([df_train, df]).reset_index(drop=True)\n",
    "\n",
    "df_train.fillna('__NaN__', inplace=True)\n",
    "\n",
    "# 强迫症发作..\n",
    "df_train = df_train.rename(columns={'lable': 'label'})\n",
    "df_train.info()\n",
    "print(len(df_train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "numpy.int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_train['label'][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "      id method                                         user_agent  \\\n0  17902    GET  Dalvik/2.1.0 (Linux; U; Android 11; SM-G9860 B...   \n1    190    GET  Dalvik/2.1.0 (Linux; U; Android 11; Mi 10 Buil...   \n2   8799    GET  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...   \n3   8788    GET  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...   \n4  16030    GET  Dalvik/2.1.0 (Linux; U; Android 9; MI 9 SE MIU...   \n\n                                                 url    refer  \\\n0  /livemsg?ad_type=WL_WK&ty=web&pu=0&openudid=ed...  __NaN__   \n1  /livemsg?ad_type=WL_WK&ty=web&pu=0&openudid=d6...  __NaN__   \n2  /(select%20extractvalue(xmltype('%3c%3fxml%20v...  __NaN__   \n3  /ftp/quarantine/?(select%20load_file('%5c%5c%5...  __NaN__   \n4  /livemsg?ad_type=WL_WK&oadid=&ty=web&pu=0&adap...  __NaN__   \n\n                                                body  label  \n0  GET /livemsg?ad_type=WL_WK&ty=web&pu=0&openudi...      1  \n1  GET /livemsg?ad_type=WL_WK&ty=web&pu=0&openudi...      1  \n2  GET /(select%20extractvalue(xmltype('%3c%3fxml...      1  \n3  GET /ftp/quarantine/?(select%20load_file('%5c%...      1  \n4  GET /livemsg?ad_type=WL_WK&oadid=&ty=web&pu=0&...      1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>method</th>\n      <th>user_agent</th>\n      <th>url</th>\n      <th>refer</th>\n      <th>body</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17902</td>\n      <td>GET</td>\n      <td>Dalvik/2.1.0 (Linux; U; Android 11; SM-G9860 B...</td>\n      <td>/livemsg?ad_type=WL_WK&amp;ty=web&amp;pu=0&amp;openudid=ed...</td>\n      <td>__NaN__</td>\n      <td>GET /livemsg?ad_type=WL_WK&amp;ty=web&amp;pu=0&amp;openudi...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>190</td>\n      <td>GET</td>\n      <td>Dalvik/2.1.0 (Linux; U; Android 11; Mi 10 Buil...</td>\n      <td>/livemsg?ad_type=WL_WK&amp;ty=web&amp;pu=0&amp;openudid=d6...</td>\n      <td>__NaN__</td>\n      <td>GET /livemsg?ad_type=WL_WK&amp;ty=web&amp;pu=0&amp;openudi...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8799</td>\n      <td>GET</td>\n      <td>Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...</td>\n      <td>/(select%20extractvalue(xmltype('%3c%3fxml%20v...</td>\n      <td>__NaN__</td>\n      <td>GET /(select%20extractvalue(xmltype('%3c%3fxml...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8788</td>\n      <td>GET</td>\n      <td>Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...</td>\n      <td>/ftp/quarantine/?(select%20load_file('%5c%5c%5...</td>\n      <td>__NaN__</td>\n      <td>GET /ftp/quarantine/?(select%20load_file('%5c%...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>16030</td>\n      <td>GET</td>\n      <td>Dalvik/2.1.0 (Linux; U; Android 9; MI 9 SE MIU...</td>\n      <td>/livemsg?ad_type=WL_WK&amp;oadid=&amp;ty=web&amp;pu=0&amp;adap...</td>\n      <td>__NaN__</td>\n      <td>GET /livemsg?ad_type=WL_WK&amp;oadid=&amp;ty=web&amp;pu=0&amp;...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "1    14038\n2     9939\n0     6489\n3     1397\n4      697\n5      659\nName: label, dtype: int64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('../data/test/test.csv')\n",
    "df_test.fillna('__NaN__', inplace=True)\n",
    "print(len(df_test))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "   id method                                         user_agent  \\\n0   0    GET  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...   \n1   1    GET  Dalvik/2.1.0 (Linux; U; Android 11; M2102J2SC ...   \n2   2    GET  Mozilla/5.0 (Windows NT 10.0; rv:78.0) Gecko/2...   \n3   3    GET                                            __NaN__   \n4   4    PUT  Mozilla/5.0 (Windows NT 10.0; rv:78.0) Gecko/2...   \n\n                                                 url  \\\n0  /demo/aisec/upload.php?act='%7C%7C(select+1+fr...   \n1  /livemsg?ad_type=WL_WK&ty=web&pu=1&openudid=5f...   \n2  /create_user/?username=%3Cscript%3Ealert(docum...   \n3  /mmsns/WeDwicXmkOl4kjKsBycicI0H3q41r6syFFvu46h...   \n4                                       /naizau.jsp/   \n\n                                               refer  \\\n0  http://demo.aisec.cn/demo/aisec/upload.php?t=0...   \n1                                            __NaN__   \n2                                            __NaN__   \n3                                            __NaN__   \n4                                            __NaN__   \n\n                                                body  \n0  GET /demo/aisec/upload.php?act='%7C%7C(select+...  \n1  GET /livemsg?ad_type=WL_WK&ty=web&pu=1&openudi...  \n2                                            __NaN__  \n3                                            __NaN__  \n4  GET /login HTTP/1.1 Host: 111.160.211.18:8088 ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>method</th>\n      <th>user_agent</th>\n      <th>url</th>\n      <th>refer</th>\n      <th>body</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>GET</td>\n      <td>Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...</td>\n      <td>/demo/aisec/upload.php?act='%7C%7C(select+1+fr...</td>\n      <td>http://demo.aisec.cn/demo/aisec/upload.php?t=0...</td>\n      <td>GET /demo/aisec/upload.php?act='%7C%7C(select+...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>GET</td>\n      <td>Dalvik/2.1.0 (Linux; U; Android 11; M2102J2SC ...</td>\n      <td>/livemsg?ad_type=WL_WK&amp;ty=web&amp;pu=1&amp;openudid=5f...</td>\n      <td>__NaN__</td>\n      <td>GET /livemsg?ad_type=WL_WK&amp;ty=web&amp;pu=1&amp;openudi...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>GET</td>\n      <td>Mozilla/5.0 (Windows NT 10.0; rv:78.0) Gecko/2...</td>\n      <td>/create_user/?username=%3Cscript%3Ealert(docum...</td>\n      <td>__NaN__</td>\n      <td>__NaN__</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>GET</td>\n      <td>__NaN__</td>\n      <td>/mmsns/WeDwicXmkOl4kjKsBycicI0H3q41r6syFFvu46h...</td>\n      <td>__NaN__</td>\n      <td>__NaN__</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>PUT</td>\n      <td>Mozilla/5.0 (Windows NT 10.0; rv:78.0) Gecko/2...</td>\n      <td>/naizau.jsp/</td>\n      <td>__NaN__</td>\n      <td>GET /login HTTP/1.1 Host: 111.160.211.18:8088 ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class My_Dataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len, test_mode):\n",
    "        self.method = df['method'].values\n",
    "        self.user_agent = df['user_agent'].values\n",
    "        self.url = df['url'].values\n",
    "        self.refer = df['refer'].values\n",
    "        self.body = df['body'].values\n",
    "        if not test_mode:\n",
    "            self.label = df['label'].values\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.test_mode = test_mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.method)\n",
    "\n",
    "\n",
    "    def tokenize_text(self, text: str, max_len=512) -> tuple:\n",
    "\n",
    "        encoded_inputs = self.tokenizer(text, max_length=max_len, padding='max_length', truncation=True)\n",
    "        input_ids = torch.LongTensor(encoded_inputs['input_ids'])\n",
    "        mask = torch.LongTensor(encoded_inputs['attention_mask'])\n",
    "        return input_ids, mask\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "\n",
    "        method_maxlen = 4\n",
    "        user_agent_maxlen = 60\n",
    "        url_maxlen = 128\n",
    "        refer_maxlen = 60\n",
    "        body_maxlen = 256\n",
    "\n",
    "        method = self.method[idx]\n",
    "        user_agent = self.user_agent[idx]\n",
    "        url = self.url[idx]\n",
    "        refer = self.refer[idx]\n",
    "        body = self.body[idx]\n",
    "\n",
    "        # sep: '</s>'\n",
    "\n",
    "        if len(method)>method_maxlen:\n",
    "            method= method[:method_maxlen//2]+method[-(method_maxlen//2):]\n",
    "\n",
    "        if len(user_agent)>user_agent_maxlen:\n",
    "            user_agent = user_agent[:user_agent_maxlen//2]+user_agent[-(user_agent_maxlen//2):]\n",
    "\n",
    "        if len(url)>url_maxlen:\n",
    "            url = url[:url_maxlen//2]+url[-(url_maxlen//2):]\n",
    "\n",
    "\n",
    "        if len(refer)>refer_maxlen:\n",
    "            refer = refer[:refer_maxlen//2]+refer[-(refer_maxlen//2):]\n",
    "\n",
    "        if len(body)>body_maxlen:\n",
    "            body = body[:body_maxlen//2]+body[-(body_maxlen//2):]\n",
    "\n",
    "\n",
    "        cat_text = method+'</s>'+body+'</s>'+user_agent+'</s>'+url+'</s>'+refer\n",
    "        cat_input, cat_mask = self.tokenize_text(cat_text, max_len=self.max_len)\n",
    "\n",
    "        sample = dict(\n",
    "            input_ids=cat_input,\n",
    "            attention_mask=cat_mask\n",
    "        )\n",
    "\n",
    "\n",
    "        if not self.test_mode:\n",
    "            sample['label'] = torch.LongTensor([self.label[idx]])\n",
    "\n",
    "        return sample\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size, test_mode=False):\n",
    "    ds=My_Dataset(\n",
    "        df=df,\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=max_len,\n",
    "        test_mode=test_mode\n",
    "    )\n",
    "    if test_mode:\n",
    "        return DataLoader(ds, batch_size=batch_size, shuffle=False)\n",
    "    else:\n",
    "        return DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# len(train_data_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# data = next(iter(train_data_loader))\n",
    "# data.keys()\n",
    "# print(data['input_ids'].shape)\n",
    "# print(data['attention_mask'].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# for inputs in train_data_loader:\n",
    "#     print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# inputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('use device: ', device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "class WebAttack_Classfier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bert_cnofig = RobertaConfig.from_pretrained(PRE_TRAINED_MODEL_PATH + './config.json')\n",
    "        self.bert = RobertaModel.from_pretrained(PRE_TRAINED_MODEL_PATH, config=self.bert_cnofig)\n",
    "        self.fc = nn.Linear(768, 6)\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_ids = inputs['input_ids'].to(device)\n",
    "        attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "        output, pooled_output = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=False\n",
    "        )\n",
    "\n",
    "        # out = self.fc(pooled_output)\n",
    "\n",
    "        mean_output = output.mean(1)\n",
    "        out = self.fc(mean_output)\n",
    "\n",
    "        return out\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# y = model(data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# y.shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_optimizer(model, learning_rate, num_total_steps):\n",
    "    # Prepare optimizer and schedule (linear warmup and decay)\n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "    print('learning_rate: ', learning_rate)\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=1e-6)\n",
    "    # scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=args.warmup_steps,\n",
    "    #                                             num_training_steps=args.max_steps)\n",
    "    print('num_training_steps: ', num_total_steps)\n",
    "    print('warmup_steps: ', num_total_steps*0.1)\n",
    "    # print('num_training_steps: ', args.max_steps)\n",
    "    # print('warmup_steps: ', args.warmup_steps)\n",
    "    # scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=args.warmup_steps,\n",
    "    #                                             num_training_steps= args.max_steps)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_total_steps*0.1,\n",
    "                                                num_training_steps= num_total_steps)\n",
    "    return optimizer, scheduler\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, auc, f1_score\n",
    "# print('f1: ', f1_score(np.argmax(oof_pred, axis=1), df_train['label'], average='macro'))\n",
    "def train_epoch(args, model, data_loader, loss_fn, optimizer, device, scheduler):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "\n",
    "    pred_list = []\n",
    "    target_list = []\n",
    "\n",
    "    for inputs in tqdm(data_loader):\n",
    "        targets = inputs[\"label\"].to(device)\n",
    "        targets = targets.squeeze(1)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "\n",
    "        pred_list.extend(preds.cpu().numpy().tolist())\n",
    "        target_list.extend(targets.cpu().numpy().tolist())\n",
    "\n",
    "\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "\n",
    "\n",
    "        # -----------------------------------对抗攻击------------------------------------------------\n",
    "        if args.use_fgm:\n",
    "            # 对抗训练\n",
    "            fgm.attack()  # 在embedding上添加对抗扰动\n",
    "            outputs = model(inputs)\n",
    "            loss_adv = loss_fn(outputs, targets)\n",
    "            loss_adv.backward()  # 反向传播，并在正常的grad基础上，累加对抗训练的梯度\n",
    "            fgm.restore()  # 恢复embedding参数\n",
    "\n",
    "        if args.use_pgd:\n",
    "            pgd.backup_grad()\n",
    "            for t in range(K):\n",
    "                pgd.attack(is_first_attack=(t == 0))\n",
    "                if t != K - 1:\n",
    "                    model.zero_grad()\n",
    "                else:\n",
    "                    pgd.restore_grad()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss_adv = loss_fn(outputs, targets)\n",
    "                loss_adv.backward()  # 反向传播，并在正常的grad基础上，累加对抗训练的梯度\n",
    "\n",
    "            pgd.restore()\n",
    "\n",
    "\n",
    "        # ----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        scheduler.step()\n",
    "\n",
    "        if args.ema != False:\n",
    "            args.ema.update()\n",
    "\n",
    "\n",
    "    acc =  accuracy_score(y_true=target_list, y_pred=pred_list)\n",
    "    f1 = f1_score(y_true=target_list, y_pred=pred_list, average='macro')\n",
    "    mean_loss = np.mean(losses)\n",
    "\n",
    "    return acc, f1, mean_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def eval_model(args, model, data_loader, loss_fn, device):\n",
    "    model = model.eval() # 验证预测模式\n",
    "    if args.ema!=False:\n",
    "        args.ema.apply_shadow()\n",
    "\n",
    "\n",
    "    losses = []\n",
    "\n",
    "\n",
    "    pred_list = []\n",
    "    target_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs in tqdm(data_loader):\n",
    "            targets = inputs[\"label\"].to(device)\n",
    "            targets = targets.squeeze(1)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "\n",
    "            pred_list.extend(preds.cpu().numpy().tolist())\n",
    "            target_list.extend(targets.cpu().numpy().tolist())\n",
    "\n",
    "\n",
    "            loss = loss_fn(outputs, targets)\n",
    "\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "\n",
    "\n",
    "    acc =  accuracy_score(y_true=target_list, y_pred=pred_list)\n",
    "    f1 = f1_score(y_true=target_list, y_pred=pred_list, average='macro')\n",
    "    mean_loss = np.mean(losses)\n",
    "\n",
    "\n",
    "    return acc, f1, mean_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.ema = True\n",
    "        self.use_fgm = True\n",
    "        self.use_pgd = False\n",
    "\n",
    "args = Args()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use pretrain model:  E:/打工/预训练模型/hfl/roberta-base/\n"
     ]
    }
   ],
   "source": [
    "PRE_TRAINED_MODEL_PATH = 'E:/打工/预训练模型/hfl/roberta-base/'\n",
    "print('use pretrain model: ', PRE_TRAINED_MODEL_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "！！！！！！！！！！！kfold开始冲啊！！！！！！！！！！！\n",
      "--------------------\n",
      "******************** 第 1 折 ing.... ********************\n",
      "train_set_len:  1600 dev_set_len:  400\n",
      "EPOCH:  1\n",
      "learning_rate:  2e-05\n",
      "num_training_steps:  50\n",
      "warmup_steps:  5.0\n",
      "---------- 采用EMA机制训练 ----------\n",
      "---------- 采用FGM对抗训练 ----------\n",
      "Epoch 1/1\n",
      "----------\n",
      "train_loss: 0.2930969069886487 \n",
      " train_acc: 0.89875 \n",
      " train_f1: 0.47333772218564846\n",
      "val_loss: 1.7749531544171846 \n",
      " val_acc: 0.0 \n",
      " val_f1: 0.0\n",
      "\n",
      "best model saved!!!!!!!!!!!!!\n",
      "******************** 第 2 折 ing.... ********************\n",
      "train_set_len:  1600 dev_set_len:  400\n",
      "EPOCH:  1\n",
      "learning_rate:  2e-05\n",
      "num_training_steps:  50\n",
      "warmup_steps:  5.0\n",
      "---------- 采用FGM对抗训练 ----------\n",
      "Epoch 1/1\n",
      "----------\n",
      "train_loss: 0.30377004902402405 \n",
      " train_acc: 0.911875 \n",
      " train_f1: 0.23847662634847988\n",
      "val_loss: 0.00023503872440554775 \n",
      " val_acc: 1.0 \n",
      " val_f1: 1.0\n",
      "\n",
      "best model saved!!!!!!!!!!!!!\n",
      "******************** 第 3 折 ing.... ********************\n",
      "train_set_len:  1600 dev_set_len:  400\n",
      "EPOCH:  1\n",
      "learning_rate:  2e-05\n",
      "num_training_steps:  50\n",
      "warmup_steps:  5.0\n",
      "---------- 采用FGM对抗训练 ----------\n",
      "Epoch 1/1\n",
      "----------\n",
      "train_loss: 0.25811282951093745 \n",
      " train_acc: 0.95 \n",
      " train_f1: 0.48717948717948717\n",
      "val_loss: 0.0002662886466938429 \n",
      " val_acc: 1.0 \n",
      " val_f1: 1.0\n",
      "\n",
      "best model saved!!!!!!!!!!!!!\n",
      "******************** 第 4 折 ing.... ********************\n",
      "train_set_len:  1600 dev_set_len:  400\n",
      "EPOCH:  1\n",
      "learning_rate:  2e-05\n",
      "num_training_steps:  50\n",
      "warmup_steps:  5.0\n",
      "---------- 采用FGM对抗训练 ----------\n",
      "Epoch 1/1\n",
      "----------\n",
      "train_loss: 0.2492114213842433 \n",
      " train_acc: 0.9725 \n",
      " train_f1: 0.4930291508238276\n",
      "val_loss: 0.00032917702964578685 \n",
      " val_acc: 1.0 \n",
      " val_f1: 1.0\n",
      "\n",
      "best model saved!!!!!!!!!!!!!\n",
      "******************** 第 5 折 ing.... ********************\n",
      "train_set_len:  1600 dev_set_len:  400\n",
      "EPOCH:  1\n",
      "learning_rate:  2e-05\n",
      "num_training_steps:  50\n",
      "warmup_steps:  5.0\n",
      "---------- 采用FGM对抗训练 ----------\n",
      "Epoch 1/1\n",
      "----------\n",
      "train_loss: 0.26194121815729887 \n",
      " train_acc: 0.95375 \n",
      " train_f1: 0.48816378758797185\n",
      "val_loss: 0.000332912096592526 \n",
      " val_acc: 1.0 \n",
      " val_f1: 1.0\n",
      "\n",
      "best model saved!!!!!!!!!!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at E:/打工/预训练模型/hfl/roberta-base/ were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.42it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 20.22it/s]\n",
      "Some weights of the model checkpoint at E:/打工/预训练模型/hfl/roberta-base/ were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.50it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 19.94it/s]\n",
      "Some weights of the model checkpoint at E:/打工/预训练模型/hfl/roberta-base/ were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.39it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 19.15it/s]\n",
      "Some weights of the model checkpoint at E:/打工/预训练模型/hfl/roberta-base/ were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.23it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 18.75it/s]\n",
      "Some weights of the model checkpoint at E:/打工/预训练模型/hfl/roberta-base/ were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.20it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 17.07it/s]\n"
     ]
    }
   ],
   "source": [
    "print('-'*20)\n",
    "print('！！！！！！！！！！！kfold开始冲啊！！！！！！！！！！！')\n",
    "print('-' * 20)\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from collections import defaultdict\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df_train, df_train['label'])):\n",
    "\n",
    "\n",
    "    print('**' * 10, '第', fold + 1, '折', 'ing....', '**' * 10)\n",
    "    train_data_df = df_train.iloc[train_idx]\n",
    "    train_data_df.index = range(len(train_data_df)) # 重置索引\n",
    "    val_data_df = df_train.iloc[val_idx]\n",
    "    val_data_df.index = range(len(val_data_df)) # 重置索引\n",
    "    print('train_set_len: ',len(train_data_df), 'dev_set_len: ', len(val_data_df))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(PRE_TRAINED_MODEL_PATH)\n",
    "    train_data_loader = create_data_loader(df=train_data_df,\n",
    "                       tokenizer=tokenizer,\n",
    "                       max_len=32,\n",
    "                       batch_size=32,\n",
    "                       test_mode=False)\n",
    "\n",
    "    val_data_loader = create_data_loader(df=val_data_df,\n",
    "                       tokenizer=tokenizer,\n",
    "                       max_len=32,\n",
    "                       batch_size=32,\n",
    "                       test_mode=False)\n",
    "\n",
    "\n",
    "    # 每一折实例化新模型\n",
    "    model = WebAttack_Classfier()\n",
    "    model = model.to(device)\n",
    "\n",
    "    EPOCHS = 1 # 训练轮数\n",
    "    print('EPOCH: ', EPOCHS)\n",
    "    total_steps = len(train_data_loader) * EPOCHS\n",
    "    optimizer, scheduler = build_optimizer(model, learning_rate=2e-5, num_total_steps=total_steps)\n",
    "\n",
    "\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "\n",
    "    if args.ema==True:\n",
    "        print('-'*10,'采用EMA机制训练','-'*10)\n",
    "        from tricks import EMA\n",
    "        args.ema = EMA(model, 0.999)\n",
    "        args.ema.register()\n",
    "\n",
    "    if args.use_fgm==True:\n",
    "        print('-' * 10, '采用FGM对抗训练', '-' * 10)\n",
    "        from tricks import FGM\n",
    "        # 初始化\n",
    "        fgm = FGM(model)\n",
    "\n",
    "    if args.use_pgd==True:\n",
    "        print('-' * 10, '采用PGD对抗训练', '-' * 10)\n",
    "        from tricks import PGD\n",
    "        # 初始化\n",
    "        pgd = PGD(model=model)\n",
    "        K = 3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    history = defaultdict(list) # 记录10轮loss和acc\n",
    "    best_f1 = 0\n",
    "\n",
    "\n",
    "    # -------------------控制早停--------------\n",
    "    early_stop_epochs = 2\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        train_acc, train_f1, train_loss = train_epoch(\n",
    "            args,\n",
    "            model,\n",
    "            train_data_loader,\n",
    "            loss_fn,\n",
    "            optimizer,\n",
    "            device,\n",
    "            scheduler\n",
    "        )\n",
    "\n",
    "        print(f'train_loss: {train_loss} \\n train_acc: {train_acc} \\n train_f1: {train_f1}')\n",
    "\n",
    "        val_acc, val_f1, val_loss = eval_model(\n",
    "            args,\n",
    "            model,\n",
    "            val_data_loader,\n",
    "            loss_fn,\n",
    "            device\n",
    "        )\n",
    "\n",
    "        print(f'val_loss: {val_loss} \\n val_acc: {val_acc} \\n val_f1: {val_f1}')\n",
    "        print()\n",
    "\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['train_f1'].append(train_f1)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_f1'].append(val_f1)\n",
    "        history['val_loss'].append(val_loss)\n",
    "\n",
    "        if val_f1 >= best_f1:\n",
    "            print('best model saved!!!!!!!!!!!!!')\n",
    "            torch.save(model.state_dict(), f'./save model/best_model_{fold+1}fold.bin')\n",
    "            best_f1 = val_f1\n",
    "\n",
    "            no_improve_epochs = 0\n",
    "\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "\n",
    "\n",
    "\n",
    "        if no_improve_epochs == early_stop_epochs:\n",
    "            print('no improve score !!! stop train !!!')\n",
    "            break\n",
    "\n",
    "\n",
    "        if args.ema != False:\n",
    "            args.ema.restore()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}